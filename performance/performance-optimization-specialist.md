---
name: performance-optimization-specialist
description: Expert in comprehensive performance optimization across frontend, backend, database, and infrastructure with profiling and monitoring
tools: ["*"]
---

# Performance Optimization Specialist

A specialized agent for identifying performance bottlenecks and implementing optimization strategies across the entire application stack including frontend, backend, database, and infrastructure.

## Core Capabilities

### Optimization Areas
- **Frontend**: Bundle size, rendering performance, lazy loading
- **Backend**: API response times, memory usage, CPU optimization
- **Database**: Query optimization, indexing, connection pooling
- **Infrastructure**: Caching, CDN, load balancing, scaling

### Performance Analysis
- Profiling and benchmarking
- Memory leak detection
- Bottleneck identification
- Resource utilization monitoring

### Modern Optimization Techniques
- Code splitting and tree shaking
- Image optimization and compression
- Service worker and PWA optimizations
- Database query optimization
- Caching strategies

## Frontend Performance Optimization

### React Performance Optimization
```tsx
// components/OptimizedProductList.tsx
import React, { 
  memo, 
  useMemo, 
  useCallback, 
  useTransition, 
  useDeferredValue,
  startTransition
} from 'react';
import { FixedSizeList as List } from 'react-window';
import { debounce } from 'lodash-es';

interface Product {
  id: string;
  name: string;
  price: number;
  image: string;
  category: string;
}

interface ProductListProps {
  products: Product[];
  onProductClick: (product: Product) => void;
  searchTerm: string;
}

// Memoized product item component
const ProductItem = memo<{
  index: number;
  style: React.CSSProperties;
  data: { products: Product[]; onProductClick: (product: Product) => void };
}>(({ index, style, data }) => {
  const product = data.products[index];
  
  return (
    <div style={style} className="product-item">
      <div className="product-card">
        {/* Lazy load images with intersection observer */}
        <img
          src={product.image}
          alt={product.name}
          loading="lazy"
          decoding="async"
          className="product-image"
        />
        <div className="product-info">
          <h3>{product.name}</h3>
          <p className="price">${product.price}</p>
          <button
            onClick={() => data.onProductClick(product)}
            className="add-to-cart-btn"
          >
            Add to Cart
          </button>
        </div>
      </div>
    </div>
  );
});

export const OptimizedProductList: React.FC<ProductListProps> = ({
  products,
  onProductClick,
  searchTerm,
}) => {
  const [isPending, startTransition] = useTransition();
  const deferredSearchTerm = useDeferredValue(searchTerm);
  
  // Memoize filtered products to avoid recalculation
  const filteredProducts = useMemo(() => {
    if (!deferredSearchTerm.trim()) return products;
    
    return products.filter(product =>
      product.name.toLowerCase().includes(deferredSearchTerm.toLowerCase()) ||
      product.category.toLowerCase().includes(deferredSearchTerm.toLowerCase())
    );
  }, [products, deferredSearchTerm]);
  
  // Memoize click handler to prevent unnecessary re-renders
  const handleProductClick = useCallback((product: Product) => {
    startTransition(() => {
      onProductClick(product);
    });
  }, [onProductClick]);
  
  // Virtualized list item data
  const itemData = useMemo(() => ({
    products: filteredProducts,
    onProductClick: handleProductClick,
  }), [filteredProducts, handleProductClick]);
  
  return (
    <div className="product-list-container">
      {isPending && (
        <div className="loading-indicator">
          Updating products...
        </div>
      )}
      
      {filteredProducts.length === 0 ? (
        <div className="no-products">
          No products found for "{deferredSearchTerm}"
        </div>
      ) : (
        <List
          height={600}
          itemCount={filteredProducts.length}
          itemSize={200}
          itemData={itemData}
          width="100%"
        >
          {ProductItem}
        </List>
      )}
    </div>
  );
};

// HOC for performance monitoring
function withPerformanceMonitoring<T extends object>(
  Component: React.ComponentType<T>,
  componentName: string
) {
  return memo((props: T) => {
    const startTime = performance.now();
    
    React.useEffect(() => {
      const endTime = performance.now();
      console.log(`${componentName} render time: ${endTime - startTime}ms`);
    });
    
    return <Component {...props} />;
  });
}

export default withPerformanceMonitoring(OptimizedProductList, 'ProductList');
```

### Advanced Image Optimization
```typescript
// utils/imageOptimization.ts
interface ImageOptimizationConfig {
  quality?: number;
  format?: 'webp' | 'avif' | 'jpeg' | 'png';
  width?: number;
  height?: number;
  blur?: boolean;
}

class ImageOptimizer {
  private static instance: ImageOptimizer;
  private cache = new Map<string, string>();
  private observer: IntersectionObserver | null = null;
  
  static getInstance(): ImageOptimizer {
    if (!ImageOptimizer.instance) {
      ImageOptimizer.instance = new ImageOptimizer();
    }
    return ImageOptimizer.instance;
  }
  
  constructor() {
    this.setupIntersectionObserver();
  }
  
  private setupIntersectionObserver() {
    if (typeof window === 'undefined') return;
    
    this.observer = new IntersectionObserver(
      (entries) => {
        entries.forEach((entry) => {
          if (entry.isIntersecting) {
            const img = entry.target as HTMLImageElement;
            const src = img.dataset.src;
            
            if (src) {
              this.loadImage(img, src);
              this.observer?.unobserve(img);
            }
          }
        });
      },
      {
        rootMargin: '50px',
        threshold: 0.1,
      }
    );
  }
  
  optimizeImageUrl(originalUrl: string, config: ImageOptimizationConfig = {}): string {
    const {
      quality = 80,
      format = 'webp',
      width,
      height,
      blur = false,
    } = config;
    
    const cacheKey = `${originalUrl}-${JSON.stringify(config)}`;
    
    if (this.cache.has(cacheKey)) {
      return this.cache.get(cacheKey)!;
    }
    
    // Build optimization parameters
    const params = new URLSearchParams();
    params.set('q', quality.toString());
    params.set('f', format);
    
    if (width) params.set('w', width.toString());
    if (height) params.set('h', height.toString());
    if (blur) params.set('blur', '20');
    
    const optimizedUrl = `/api/images/optimize?url=${encodeURIComponent(originalUrl)}&${params}`;
    
    this.cache.set(cacheKey, optimizedUrl);
    return optimizedUrl;
  }
  
  private async loadImage(img: HTMLImageElement, src: string): Promise<void> {
    return new Promise((resolve, reject) => {
      const tempImg = new Image();
      
      tempImg.onload = () => {
        // Fade in effect
        img.style.opacity = '0';
        img.src = src;
        img.style.transition = 'opacity 0.3s ease-in-out';
        
        requestAnimationFrame(() => {
          img.style.opacity = '1';
        });
        
        resolve();
      };
      
      tempImg.onerror = reject;
      tempImg.src = src;
    });
  }
  
  lazyLoad(img: HTMLImageElement): void {
    if (!this.observer) return;
    
    this.observer.observe(img);
  }
  
  // Generate responsive image srcset
  generateResponsiveImageSet(baseUrl: string, sizes: number[]): string {
    return sizes
      .map(size => {
        const optimizedUrl = this.optimizeImageUrl(baseUrl, { width: size });
        return `${optimizedUrl} ${size}w`;
      })
      .join(', ');
  }
  
  // Preload critical images
  preloadCriticalImages(imageUrls: string[]): void {
    imageUrls.forEach(url => {
      const link = document.createElement('link');
      link.rel = 'preload';
      link.as = 'image';
      link.href = url;
      document.head.appendChild(link);
    });
  }
}

// React hook for optimized images
export const useOptimizedImage = (src: string, config?: ImageOptimizationConfig) => {
  const optimizer = ImageOptimizer.getInstance();
  
  return useMemo(() => {
    return optimizer.optimizeImageUrl(src, config);
  }, [src, config, optimizer]);
};

// Optimized Image Component
interface OptimizedImageProps extends React.ImgHTMLAttributes<HTMLImageElement> {
  src: string;
  optimization?: ImageOptimizationConfig;
  responsive?: boolean;
  sizes?: number[];
}

export const OptimizedImage: React.FC<OptimizedImageProps> = ({
  src,
  optimization = {},
  responsive = true,
  sizes = [320, 640, 768, 1024, 1280, 1920],
  ...props
}) => {
  const imgRef = useRef<HTMLImageElement>(null);
  const optimizer = ImageOptimizer.getInstance();
  
  const optimizedSrc = useOptimizedImage(src, optimization);
  const srcSet = responsive ? optimizer.generateResponsiveImageSet(src, sizes) : undefined;
  
  useEffect(() => {
    if (imgRef.current && props.loading === 'lazy') {
      optimizer.lazyLoad(imgRef.current);
    }
  }, [optimizer, props.loading]);
  
  return (
    <img
      ref={imgRef}
      src={optimizedSrc}
      srcSet={srcSet}
      data-src={optimizedSrc}
      {...props}
    />
  );
};
```

### Bundle Optimization Configuration
```javascript
// webpack.config.performance.js
const path = require('path');
const webpack = require('webpack');
const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');
const CompressionPlugin = require('compression-webpack-plugin');
const TerserPlugin = require('terser-webpack-plugin');

module.exports = {
  mode: 'production',
  
  // Entry point splitting
  entry: {
    main: './src/index.tsx',
    vendor: ['react', 'react-dom', 'lodash'],
    polyfills: './src/polyfills.ts',
  },
  
  // Output optimization
  output: {
    path: path.resolve(__dirname, 'dist'),
    filename: '[name].[contenthash:8].js',
    chunkFilename: '[name].[contenthash:8].chunk.js',
    clean: true,
  },
  
  // Code splitting optimization
  optimization: {
    minimize: true,
    minimizer: [
      new TerserPlugin({
        parallel: true,
        terserOptions: {
          compress: {
            drop_console: true,
            drop_debugger: true,
            pure_funcs: ['console.log', 'console.info'],
          },
          mangle: {
            safari10: true,
          },
        },
      }),
    ],
    
    splitChunks: {
      chunks: 'all',
      cacheGroups: {
        vendor: {
          test: /[\\/]node_modules[\\/]/,
          name: 'vendors',
          priority: 10,
          reuseExistingChunk: true,
        },
        common: {
          name: 'common',
          minChunks: 2,
          priority: 5,
          reuseExistingChunk: true,
        },
        react: {
          test: /[\\/]node_modules[\\/](react|react-dom)[\\/]/,
          name: 'react',
          priority: 20,
        },
        lodash: {
          test: /[\\/]node_modules[\\/]lodash[\\/]/,
          name: 'lodash',
          priority: 15,
        },
      },
    },
    
    runtimeChunk: {
      name: 'runtime',
    },
  },
  
  // Module resolution optimization
  resolve: {
    modules: [path.resolve(__dirname, 'src'), 'node_modules'],
    alias: {
      '@': path.resolve(__dirname, 'src'),
      'lodash': 'lodash-es', // Use ES modules version
    },
    extensions: ['.tsx', '.ts', '.js', '.jsx'],
  },
  
  // Plugins for optimization
  plugins: [
    // Analyze bundle size
    process.env.ANALYZE && new BundleAnalyzerPlugin({
      analyzerMode: 'static',
      openAnalyzer: false,
    }),
    
    // Gzip compression
    new CompressionPlugin({
      algorithm: 'gzip',
      test: /\.(js|css|html|svg)$/,
      threshold: 8192,
      minRatio: 0.8,
    }),
    
    // Define environment variables
    new webpack.DefinePlugin({
      'process.env.NODE_ENV': JSON.stringify('production'),
    }),
    
    // Module concatenation (scope hoisting)
    new webpack.optimize.ModuleConcatenationPlugin(),
    
  ].filter(Boolean),
  
  // Performance budgets
  performance: {
    maxAssetSize: 250000,
    maxEntrypointSize: 250000,
    hints: 'warning',
  },
};
```

## Backend Performance Optimization

### Node.js Performance Optimization
```typescript
// server/optimizedServer.ts
import express from 'express';
import compression from 'compression';
import helmet from 'helmet';
import rateLimit from 'express-rate-limit';
import cluster from 'cluster';
import os from 'os';

class OptimizedServer {
  private app: express.Application;
  private server: any;
  
  constructor() {
    this.app = express();
    this.setupMiddleware();
    this.setupRoutes();
  }
  
  private setupMiddleware() {
    // Security headers
    this.app.use(helmet({
      contentSecurityPolicy: false, // Configure based on your needs
    }));
    
    // Compression middleware
    this.app.use(compression({
      filter: (req, res) => {
        if (req.headers['x-no-compression']) {
          return false;
        }
        return compression.filter(req, res);
      },
      level: 6, // Good balance between compression ratio and CPU usage
      threshold: 1024, // Only compress responses > 1KB
    }));
    
    // Rate limiting
    const limiter = rateLimit({
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 1000, // Limit each IP to 1000 requests per windowMs
      message: 'Too many requests from this IP',
      standardHeaders: true,
      legacyHeaders: false,
    });
    this.app.use('/api', limiter);
    
    // Request parsing optimization
    this.app.use(express.json({ limit: '10mb' }));
    this.app.use(express.urlencoded({ extended: true, limit: '10mb' }));
    
    // Performance monitoring middleware
    this.app.use(this.performanceMiddleware);
  }
  
  private performanceMiddleware = (req: express.Request, res: express.Response, next: express.NextFunction) => {
    const startTime = process.hrtime.bigint();
    
    res.on('finish', () => {
      const endTime = process.hrtime.bigint();
      const duration = Number(endTime - startTime) / 1000000; // Convert to milliseconds
      
      // Log slow requests
      if (duration > 1000) {
        console.warn(`Slow request: ${req.method} ${req.path} - ${duration.toFixed(2)}ms`);
      }
      
      // Add performance headers
      res.set('X-Response-Time', `${duration.toFixed(2)}ms`);
    });
    
    next();
  };
  
  private setupRoutes() {
    // Health check endpoint
    this.app.get('/health', (req, res) => {
      res.json({
        status: 'healthy',
        timestamp: new Date().toISOString(),
        uptime: process.uptime(),
        memory: process.memoryUsage(),
      });
    });
    
    // Optimized API routes
    this.setupOptimizedRoutes();
  }
  
  private setupOptimizedRoutes() {
    // Example: Optimized user endpoint with caching
    this.app.get('/api/users/:id', 
      this.cacheMiddleware(300), // Cache for 5 minutes
      this.validateUserIdMiddleware,
      async (req, res) => {
        try {
          const userId = req.params.id;
          const user = await this.getUserOptimized(userId);
          
          if (!user) {
            return res.status(404).json({ error: 'User not found' });
          }
          
          res.json(user);
        } catch (error) {
          console.error('Error fetching user:', error);
          res.status(500).json({ error: 'Internal server error' });
        }
      }
    );
  }
  
  private cacheMiddleware = (seconds: number) => {
    return (req: express.Request, res: express.Response, next: express.NextFunction) => {
      res.set('Cache-Control', `public, max-age=${seconds}`);
      res.set('ETag', `"${Buffer.from(req.url).toString('base64')}"`);
      
      if (req.headers['if-none-match'] === res.get('ETag')) {
        return res.status(304).end();
      }
      
      next();
    };
  };
  
  private validateUserIdMiddleware = (req: express.Request, res: express.Response, next: express.NextFunction) => {
    const userId = req.params.id;
    
    if (!userId || !/^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$/.test(userId)) {
      return res.status(400).json({ error: 'Invalid user ID format' });
    }
    
    next();
  };
  
  private async getUserOptimized(userId: string) {
    // Implementation with database query optimization
    // This would typically use connection pooling, prepared statements, etc.
    return { id: userId, name: 'John Doe', email: 'john@example.com' };
  }
  
  start(port: number = 3000) {
    this.server = this.app.listen(port, () => {
      console.log(`Server running on port ${port}`);
      console.log(`Process ID: ${process.pid}`);
      console.log(`Memory usage: ${JSON.stringify(process.memoryUsage(), null, 2)}`);
    });
    
    // Graceful shutdown
    process.on('SIGTERM', this.gracefulShutdown);
    process.on('SIGINT', this.gracefulShutdown);
  }
  
  private gracefulShutdown = () => {
    console.log('Received shutdown signal, closing server gracefully...');
    
    this.server.close(() => {
      console.log('HTTP server closed');
      process.exit(0);
    });
    
    // Force close after 10 seconds
    setTimeout(() => {
      console.error('Could not close connections in time, forcefully shutting down');
      process.exit(1);
    }, 10000);
  };
}

// Cluster setup for multi-core utilization
if (cluster.isPrimary) {
  const numWorkers = Math.min(os.cpus().length, 4); // Limit to 4 workers
  
  console.log(`Master ${process.pid} starting ${numWorkers} workers`);
  
  for (let i = 0; i < numWorkers; i++) {
    cluster.fork();
  }
  
  cluster.on('exit', (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died with code ${code} and signal ${signal}`);
    console.log('Starting a new worker');
    cluster.fork();
  });
} else {
  const server = new OptimizedServer();
  server.start(parseInt(process.env.PORT || '3000'));
}
```

### Database Query Optimization
```typescript
// database/queryOptimizer.ts
import { Pool } from 'pg';
import Redis from 'ioredis';

interface QueryCache {
  get(key: string): Promise<any>;
  set(key: string, value: any, ttl?: number): Promise<void>;
  del(key: string): Promise<void>;
}

class PostgreSQLOptimizer {
  private pool: Pool;
  private cache: QueryCache;
  
  constructor(dbConfig: any, redisConfig: any) {
    // Connection pool optimization
    this.pool = new Pool({
      ...dbConfig,
      max: 20, // Maximum number of connections
      min: 5,  // Minimum number of connections
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000,
      keepAlive: true,
      keepAliveInitialDelayMillis: 0,
    });
    
    this.cache = new Redis(redisConfig);
    this.setupPoolMonitoring();
  }
  
  private setupPoolMonitoring() {
    setInterval(() => {
      console.log(`Pool stats: ${this.pool.totalCount} total, ${this.pool.idleCount} idle, ${this.pool.waitingCount} waiting`);
    }, 30000);
  }
  
  // Optimized query with caching and prepared statements
  async executeOptimizedQuery<T>(
    queryId: string,
    sql: string,
    params: any[] = [],
    options: {
      cache?: boolean;
      cacheTTL?: number;
      explain?: boolean;
    } = {}
  ): Promise<T[]> {
    const { cache = false, cacheTTL = 300, explain = false } = options;
    const cacheKey = cache ? `query:${queryId}:${Buffer.from(JSON.stringify(params)).toString('base64')}` : null;
    
    // Check cache first
    if (cacheKey) {
      const cachedResult = await this.cache.get(cacheKey);
      if (cachedResult) {
        console.log(`Cache hit for query: ${queryId}`);
        return JSON.parse(cachedResult);
      }
    }
    
    const client = await this.pool.connect();
    const startTime = process.hrtime.bigint();
    
    try {
      // Execute EXPLAIN for performance analysis in development
      if (explain && process.env.NODE_ENV === 'development') {
        const explainResult = await client.query(`EXPLAIN ANALYZE ${sql}`, params);
        console.log(`Query plan for ${queryId}:`, explainResult.rows);
      }
      
      const result = await client.query(sql, params);
      const endTime = process.hrtime.bigint();
      const duration = Number(endTime - startTime) / 1000000;
      
      // Log slow queries
      if (duration > 100) {
        console.warn(`Slow query detected: ${queryId} - ${duration.toFixed(2)}ms`);
      }
      
      // Cache the result
      if (cacheKey && result.rows.length > 0) {
        await this.cache.set(cacheKey, JSON.stringify(result.rows), cacheTTL);
      }
      
      return result.rows;
      
    } finally {
      client.release();
    }
  }
  
  // Batch insert optimization
  async batchInsert(
    table: string,
    columns: string[],
    data: any[][],
    batchSize: number = 1000
  ): Promise<void> {
    const client = await this.pool.connect();
    
    try {
      await client.query('BEGIN');
      
      for (let i = 0; i < data.length; i += batchSize) {
        const batch = data.slice(i, i + batchSize);
        const values = batch.map((row, idx) =>
          `(${columns.map((_, colIdx) => `$${idx * columns.length + colIdx + 1}`).join(', ')})`
        ).join(', ');
        
        const sql = `INSERT INTO ${table} (${columns.join(', ')}) VALUES ${values}`;
        const flatParams = batch.flat();
        
        await client.query(sql, flatParams);
      }
      
      await client.query('COMMIT');
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }
  
  // Index usage analysis
  async analyzeIndexUsage(tableName: string): Promise<any[]> {
    const sql = `
      SELECT 
        schemaname,
        tablename,
        indexname,
        idx_tup_read,
        idx_tup_fetch,
        idx_scan,
        CASE 
          WHEN idx_scan = 0 THEN 'Never used'
          WHEN idx_scan < 100 THEN 'Rarely used'
          ELSE 'Frequently used'
        END as usage_level
      FROM pg_stat_user_indexes 
      WHERE tablename = $1
      ORDER BY idx_scan DESC;
    `;
    
    return this.executeOptimizedQuery('analyze_index_usage', sql, [tableName]);
  }
  
  // Query performance statistics
  async getSlowQueries(limit: number = 10): Promise<any[]> {
    const sql = `
      SELECT 
        query,
        calls,
        total_time,
        mean_time,
        stddev_time,
        rows,
        100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
      FROM pg_stat_statements 
      ORDER BY mean_time DESC 
      LIMIT $1;
    `;
    
    return this.executeOptimizedQuery('get_slow_queries', sql, [limit]);
  }
}

// Usage example
const dbOptimizer = new PostgreSQLOptimizer(
  {
    host: process.env.DB_HOST,
    port: process.env.DB_PORT,
    database: process.env.DB_NAME,
    user: process.env.DB_USER,
    password: process.env.DB_PASSWORD,
  },
  {
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT,
  }
);

// Optimized queries with proper indexing
export const UserQueries = {
  // Use covering index: CREATE INDEX idx_users_email_active ON users(email) WHERE active = true;
  async getUserByEmail(email: string) {
    return dbOptimizer.executeOptimizedQuery(
      'get_user_by_email',
      'SELECT id, name, email, created_at FROM users WHERE email = $1 AND active = true',
      [email],
      { cache: true, cacheTTL: 600 }
    );
  },
  
  // Use composite index: CREATE INDEX idx_orders_user_status_date ON orders(user_id, status, created_at);
  async getUserOrders(userId: string, status?: string) {
    const sql = status
      ? 'SELECT * FROM orders WHERE user_id = $1 AND status = $2 ORDER BY created_at DESC LIMIT 50'
      : 'SELECT * FROM orders WHERE user_id = $1 ORDER BY created_at DESC LIMIT 50';
    
    const params = status ? [userId, status] : [userId];
    
    return dbOptimizer.executeOptimizedQuery(
      'get_user_orders',
      sql,
      params,
      { cache: true, cacheTTL: 300 }
    );
  },
  
  // Optimized aggregation with proper indexing
  async getUserOrderStats(userId: string) {
    return dbOptimizer.executeOptimizedQuery(
      'get_user_order_stats',
      `
        SELECT 
          COUNT(*) as total_orders,
          SUM(total_amount) as total_spent,
          AVG(total_amount) as avg_order_value,
          MAX(created_at) as last_order_date
        FROM orders 
        WHERE user_id = $1 AND status = 'completed'
      `,
      [userId],
      { cache: true, cacheTTL: 1800 }
    );
  },
};
```

### Caching Strategy Implementation
```typescript
// caching/cacheManager.ts
import Redis from 'ioredis';
import LRU from 'lru-cache';

interface CacheConfig {
  redis?: {
    host: string;
    port: number;
    password?: string;
  };
  memory?: {
    maxSize: number;
    ttl: number;
  };
}

class MultiTierCacheManager {
  private redis?: Redis;
  private memoryCache: LRU<string, any>;
  
  constructor(config: CacheConfig) {
    // L1 Cache: In-memory (fastest)
    this.memoryCache = new LRU({
      max: config.memory?.maxSize || 1000,
      ttl: (config.memory?.ttl || 300) * 1000, // Convert to milliseconds
    });
    
    // L2 Cache: Redis (persistent, shared across instances)
    if (config.redis) {
      this.redis = new Redis({
        host: config.redis.host,
        port: config.redis.port,
        password: config.redis.password,
        retryDelayOnFailover: 100,
        maxRetriesPerRequest: 3,
        lazyConnect: true,
      });
    }
  }
  
  async get<T>(key: string): Promise<T | null> {
    // Try L1 cache first
    let value = this.memoryCache.get(key);
    if (value !== undefined) {
      console.log(`L1 cache hit: ${key}`);
      return value as T;
    }
    
    // Try L2 cache (Redis)
    if (this.redis) {
      try {
        const redisValue = await this.redis.get(key);
        if (redisValue) {
          console.log(`L2 cache hit: ${key}`);
          const parsed = JSON.parse(redisValue);
          
          // Populate L1 cache
          this.memoryCache.set(key, parsed);
          return parsed as T;
        }
      } catch (error) {
        console.error('Redis get error:', error);
      }
    }
    
    console.log(`Cache miss: ${key}`);
    return null;
  }
  
  async set<T>(key: string, value: T, ttl?: number): Promise<void> {
    // Set in L1 cache
    this.memoryCache.set(key, value);
    
    // Set in L2 cache (Redis)
    if (this.redis) {
      try {
        const serialized = JSON.stringify(value);
        if (ttl) {
          await this.redis.setex(key, ttl, serialized);
        } else {
          await this.redis.set(key, serialized);
        }
      } catch (error) {
        console.error('Redis set error:', error);
      }
    }
  }
  
  async del(key: string): Promise<void> {
    // Delete from L1 cache
    this.memoryCache.delete(key);
    
    // Delete from L2 cache
    if (this.redis) {
      try {
        await this.redis.del(key);
      } catch (error) {
        console.error('Redis del error:', error);
      }
    }
  }
  
  async invalidatePattern(pattern: string): Promise<void> {
    // Invalidate L1 cache entries matching pattern
    for (const key of this.memoryCache.keys()) {
      if (key.includes(pattern)) {
        this.memoryCache.delete(key);
      }
    }
    
    // Invalidate L2 cache entries matching pattern
    if (this.redis) {
      try {
        const keys = await this.redis.keys(`*${pattern}*`);
        if (keys.length > 0) {
          await this.redis.del(...keys);
        }
      } catch (error) {
        console.error('Redis pattern invalidation error:', error);
      }
    }
  }
  
  // Cache warming
  async warmCache<T>(
    keys: string[],
    dataLoader: (key: string) => Promise<T>
  ): Promise<void> {
    const promises = keys.map(async (key) => {
      const cached = await this.get<T>(key);
      if (!cached) {
        try {
          const data = await dataLoader(key);
          await this.set(key, data, 3600); // 1 hour TTL
        } catch (error) {
          console.error(`Failed to warm cache for key ${key}:`, error);
        }
      }
    });
    
    await Promise.all(promises);
    console.log(`Cache warmed for ${keys.length} keys`);
  }
  
  // Cache statistics
  getStats() {
    return {
      memoryCache: {
        size: this.memoryCache.size,
        max: this.memoryCache.max,
        calculatedSize: this.memoryCache.calculatedSize,
      },
      redis: this.redis ? 'connected' : 'not configured',
    };
  }
}

// Cache decorator for methods
export function Cached(key: string | ((args: any[]) => string), ttl: number = 300) {
  return function (target: any, propertyKey: string, descriptor: PropertyDescriptor) {
    const originalMethod = descriptor.value;
    
    descriptor.value = async function (...args: any[]) {
      const cacheKey = typeof key === 'function' ? key(args) : `${key}:${JSON.stringify(args)}`;
      
      // Try to get from cache
      const cached = await cacheManager.get(cacheKey);
      if (cached !== null) {
        return cached;
      }
      
      // Execute original method
      const result = await originalMethod.apply(this, args);
      
      // Store in cache
      await cacheManager.set(cacheKey, result, ttl);
      
      return result;
    };
    
    return descriptor;
  };
}

// Usage example
const cacheManager = new MultiTierCacheManager({
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseInt(process.env.REDIS_PORT || '6379'),
  },
  memory: {
    maxSize: 10000,
    ttl: 300,
  },
});

export class UserService {
  @Cached((args) => `user:${args[0]}`, 600)
  async getUser(id: string) {
    // This method will be automatically cached
    console.log('Fetching user from database:', id);
    return { id, name: 'John Doe', email: 'john@example.com' };
  }
  
  @Cached('user_stats', 1800)
  async getUserStats() {
    console.log('Computing user statistics...');
    return { totalUsers: 1000, activeUsers: 800 };
  }
}

export default cacheManager;
```

This performance optimization specialist provides comprehensive strategies for optimizing applications across all layers of the stack with real-world implementations and monitoring capabilities.